# ANN Model with MLflow Tracking, Hyperparameter Tuning, and Deployment

This project implements an **Artificial Neural Network (ANN)** using **Keras** for regression tasks, combined with:
- ğŸ”¹ **MLflow Tracking** for experiment logging
- ğŸ”¹ **Hyperopt** for hyperparameter optimization
- ğŸ”¹ **MLflow Model Registry** for model versioning
- ğŸ”¹ **MLflow Serving (REST API)** for production inference
- ğŸ”¹ **Docker containerization** for scalable cloud deployment

The goal is to provide a full end-to-end machine learning workflow from model building to deployment.

---

## ğŸš€ Features

âœ… Build a Keras-based ANN for regression  
âœ… Normalize input data using Keras preprocessing layers  
âœ… Tune hyperparameters (`learning rate`, `momentum`, etc.) using **Hyperopt**  
âœ… Track parameters, metrics, and artifacts using **MLflow UI**  
âœ… Register the best model to **MLflow Model Registry**  
âœ… Serve the model via **MLflow REST API**  
âœ… Containerize the model serving endpoint using **Docker**

---

## âš™ï¸ Technologies Used

- **Python 3.x**
- **TensorFlow / Keras**
- **MLflow**
- **Hyperopt**
- **Docker**
- **Sklearn (for data splitting and preprocessing)**

---

## ğŸ§  Model Details

The ANN model architecture:
- Input Layer: normalization (mean + variance from training set)
- Dense Layer 1: 64 units, ReLU activation
- Output Layer: 1 unit (regression output)

The model is compiled with:
- **Loss:** Mean Squared Error (MSE)
- **Optimizer:** SGD with tunable learning rate and momentum
- **Metric:** Root Mean Squared Error (RMSE)

---

## ğŸ”¬ Hyperparameter Tuning

We use **Hyperopt + TPE (Tree-structured Parzen Estimator)** for tuning:
- Learning rate (`lr`)
- Momentum (`momentum`)

Example hyperopt config:
```python
space = {
    'lr': hp.uniform('lr', np.log(1e-5),np.log(1e-1)),
    'momentum': hp.uniform('momentum', 0.0, 0.99)
}
